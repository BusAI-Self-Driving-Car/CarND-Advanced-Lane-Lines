{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Self-Driving Car Engineer Nanodegree\n",
    "\n",
    "\n",
    "## Project 2: **Advanced Lane Finding** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This project goal is to develop a pipeline to identify the lane boundaries in a real scenario. \n",
    "\n",
    "This is the advance version of the Finding Lane Lines on the Road project ([GitHub repository](https://github.com/rscova/CarND-LaneLines-P1))\n",
    "\n",
    "The pipeline is based in 6 steps:\n",
    "* 1. Camera Calibration\n",
    "* 2. Distortion Image Correction\n",
    "* 3. Color Spaces and Gradients Thresholds\n",
    "* 4. Perspective transform (Bird's Eye)\n",
    "* 5. Detect lane lines\n",
    "* 6. Determine the lane curvature\n",
    "\n",
    "To achieve that I have implemented two clases: `ImageProcessor()` and `LineFinder()`. And some naive functions.\n",
    "\n",
    "To understand this code, check first the `pipeline_step_by_step.ipynb`. This file has the pipeline explained step by step with the results of each part.\n",
    "\n",
    "If you prefer this code in a simple python file check `advance_lane_finding.py`. The advantadge is that you can see how the pipeline is working in every frame of the video online."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "import cv2\n",
    "import math, os, sys, glob\n",
    "import pickle\n",
    "\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML\n",
    "\n",
    "DRAW_IMAGES = True\n",
    "SAVE_IMAGES = False\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Processing Functions\n",
    "\n",
    "These are the basic Computer Vision Functions. They do not need to be inside a class because do not need and use additional information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getImageChannels(image,space='RGB'):\n",
    "    \"\"\"\n",
    "    Split the image in channels\n",
    "    :param image: Source image\n",
    "    :param space: Current Color space of the image\n",
    "    :return: The channels of the image\n",
    "    \"\"\"\n",
    "    if (space == 'RGB'):\n",
    "        return cv2.split(image)\n",
    "    elif (space == 'HSV'):\n",
    "        return cv2.split(cv2.cvtColor(image, cv2.COLOR_RGB2HSV))\n",
    "    elif (space == 'HLS'):\n",
    "        return cv2.split(cv2.cvtColor(image, cv2.COLOR_RGB2HLS))\n",
    "    elif (space == 'LAV'):\n",
    "        return cv2.split(cv2.cvtColor(image, cv2.COLOR_RGB2LAB))\n",
    "    elif (space == 'LUV'):\n",
    "        return cv2.split(cv2.cvtColor(image, cv2.COLOR_RGB2LUV))\n",
    "    elif (space == 'YCrCb'):\n",
    "        return cv2.split(cv2.cvtColor(image, cv2.COLOR_RGB2YCrCb))\n",
    "\n",
    "def darkenImage(image,gamma=1.0):\n",
    "    \"\"\"\n",
    "    Apply gamma correction using the lookup table\n",
    "    :param image: Source image\n",
    "    :param gamma: Gamma value\n",
    "    :return: Corrected Image\n",
    "    \"\"\"\n",
    "    gamma_inverse = 1.0 / gamma\n",
    "    lut_table = np.array([((i / 255.0) ** gamma_inverse) * 255 for i in np.arange(0, 256)]).astype(\"uint8\")\n",
    "    return cv2.LUT(image, lut_table)\n",
    "\n",
    "def binarizeImage(image,thresh=100,method=cv2.THRESH_BINARY):\n",
    "    \"\"\"\n",
    "    Binarize an image using the threshold and the method\n",
    "    :param image: Source image\n",
    "    :param thresh: Threshold value to binarizate\n",
    "    :param method: Use diverse opencv methods to binarizate: Normal, Otsu, triangle.\n",
    "    :return: Binary Image\n",
    "    \"\"\"\n",
    "    ret, binary = cv2.threshold(image,thresh,1,method)\n",
    "    return binary\n",
    "\n",
    "def getSobelGradient(image,orientation='x',thresh=(0,255)):\n",
    "    \"\"\"\n",
    "    Compute the Soble's Gradient\n",
    "    :param image: Source image\n",
    "    :param orientation: Gradient in X or Y\n",
    "    :param thresh: Threshold values to binarizate, min and max\n",
    "    :return: binary gradient &  absolute value\n",
    "    \"\"\" \n",
    "    if (orientation == 'x'):\n",
    "        sobel = cv2.Sobel(image, cv2.CV_64F, 1, 0)\n",
    "    else:\n",
    "        sobel = cv2.Sobel(image, cv2.CV_64F, 0, 1)   \n",
    "    \n",
    "    abs_sobel = np.absolute(sobel)\n",
    "    scaled_sobel = np.uint8(255*abs_sobel/np.max(abs_sobel))\n",
    "    \n",
    "    grad = np.zeros_like(scaled_sobel)\n",
    "    grad[(scaled_sobel >= thresh[0]) & (scaled_sobel <= thresh[1])] = 1\n",
    "\n",
    "    return grad,abs_sobel\n",
    "\n",
    "def getGradientMagnitude(image,grad_x,grad_y,thresh=(0,255)):\n",
    "    \"\"\"\n",
    "    Compute the Magnitude of the gradient\n",
    "    :param image: Source image\n",
    "    :param grad_x: Gradient in X \n",
    "    :param grad_y: Gradient in Y\n",
    "    :param thresh: Threshold values to binarizate, min and max\n",
    "    :return: Magnitud of the Gradient Image\n",
    "    \"\"\" \n",
    "    grad_mag = np.sqrt(grad_x**2+grad_y**2)\n",
    "    scale_factor_mag = np.max(grad_mag)/255\n",
    "    grad_mag = (grad_mag/scale_factor_mag).astype(np.uint8)\n",
    "\n",
    "    mag_binary = np.zeros_like(grad_mag)\n",
    "    mag_binary[(grad_mag >= thresh[0]) & (grad_mag <= thresh[1])] = 1\n",
    "    return mag_binary\n",
    "\n",
    "def getGradientDirection(image,abs_sobel_x,abs_sobel_y,thresh=(0,np.pi/2)):\n",
    "    \"\"\"\n",
    "    Compute the Direction of the gradient\n",
    "    :param image: Source image\n",
    "    :param abs_sobel_x: Absolute Sobel in X \n",
    "    :param abs_sobel_y: Absolute Sobel in Y\n",
    "    :param thresh: Threshold values to binarizate, min and max\n",
    "    :return: Direction of the Gradient Image\n",
    "    \"\"\" \n",
    "    grad_dirct = np.arctan2(abs_sobel_y, abs_sobel_x)\n",
    "\n",
    "    dir_binary = np.zeros_like(grad_dirct)\n",
    "    dir_binary[(grad_dirct >= thresh[0]) & (grad_dirct <= thresh[1])] = 1\n",
    "    return dir_binary\n",
    "\n",
    "def transformPerspective(image,src_points,dst_points):\n",
    "    \"\"\"\n",
    "    Transform Image Perspective to another image (Bird's eye for example)\n",
    "    :param image: Source image\n",
    "    :param src_points: Source Points of the Image\n",
    "    :param dst_points: New position of the source points in the new Image\n",
    "    :return: Transformed Image\n",
    "    \"\"\" \n",
    "    M = cv2.getPerspectiveTransform(np.float32(src_points), np.float32(dst_points))\n",
    "    return  cv2.warpPerspective(image, M,(image.shape[1],image.shape[0]))\n",
    "\n",
    "def drawROI(image,points):\n",
    "    \"\"\"\n",
    "    Draw A Polygonal Region (Region Of Interest) in the image\n",
    "    :param image: Source image\n",
    "    :param points: Source Points of the polygon\n",
    "    :return: Drawed Image\n",
    "    \"\"\" \n",
    "    result = image.copy()\n",
    "    return cv2.polylines(result,np.array([points],dtype=np.int32),True,(255,0,0),4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Processor Class\n",
    "\n",
    "This class keep the information for tranform an image in to a Bird's eye binarizate image to find the lane marks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageProcessor:\n",
    "    \"\"\"\n",
    "    Class that incorporate the high-level functions to process \n",
    "    the raw image into a binary image to compute the lane\n",
    "    \"\"\" \n",
    "    def __init__(self,img_shape=(720,1280,3)):\n",
    "        \"\"\"\n",
    "        Class constructor, all the class variables are defined here \n",
    "        :param self: referenc of the class instance\n",
    "        :param img_shape: shape of the image\n",
    "        \"\"\"\n",
    "        \n",
    "        self.img_shape_ = img_shape\n",
    "        self.img_size_  = (img_shape[1], img_shape[0])\n",
    "        \n",
    "        self.mtx_  = []\n",
    "        self.dist_ = []\n",
    "        \n",
    "        self.gamma_ = 0.7\n",
    "        \n",
    "        self.r_channel_thresh_ = 100\n",
    "        self.s_channel_thresh_ = 150\n",
    "        self.grad_x_thresh_    = (20,200)\n",
    "        self.grad_y_thresh_    = (20,200)\n",
    "        self.grad_mag_thresh_  = (10, 100)\n",
    "        self.grad_dir_thresh_  = (5*np.pi/18, 4*np.pi/9)\n",
    "    \n",
    "        self.src_points_ = [(193,720), (577,460),(705,460),(1126,720)]#[(220, 720),(570, 500),(722 , 500),(1110, 720)]#\n",
    "        self.dst_points_ = [(320,720), (320,0)  ,(960,0)  ,(960,720)]#[(320, 720),(410, 1),(790,1),(920 , 720)]#\n",
    "\n",
    "    def readImage(self,img_path):\n",
    "        \"\"\"\n",
    "        Image reader and updates the img_shape_ variable\n",
    "        :param self: referenc of the class instance\n",
    "        :param img_path: path of the image\n",
    "        :return: Image\n",
    "        \"\"\"\n",
    "        image = cv2.imread(img_path)\n",
    "        self.img_shape_ = image.shape\n",
    "        return cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    def cameraCalibration(self,img_paths=\"camera_cal/\", row_corners=9, col_corners=6):\n",
    "        \"\"\"\n",
    "        Calibration of the camera, it uses a chessboard pattern \n",
    "        Get the camera matrix (mtx_) and vector of distortion coefficients(dist_)\n",
    "        :param self: referenc of the class instance\n",
    "        :param img_paths: path of the images\n",
    "        :param row_corners: chessboard inside row corners\n",
    "        :param col_corners: chessboard inside col corners\n",
    "        \"\"\"\n",
    "        objp = np.zeros((col_corners*row_corners,3), np.float32)\n",
    "        objp[:,:2] = np.mgrid[0:row_corners, 0:col_corners].T.reshape(-1,2)\n",
    "\n",
    "        objpoints = []\n",
    "        imgpoints = []\n",
    "        \n",
    "        img_calibration_paths = glob.glob(img_paths + \"*.jpg\")\n",
    "\n",
    "        for idx,img_cal in enumerate(img_calibration_paths):\n",
    "            image = cv2.imread(img_cal)\n",
    "            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "            ret, corners = cv2.findChessboardCorners(gray, (row_corners,col_corners), None)\n",
    "\n",
    "            if ret == True:\n",
    "                objpoints.append(objp)\n",
    "                imgpoints.append(corners)\n",
    "\n",
    "                if DRAW_IMAGES:\n",
    "                    cv2.drawChessboardCorners(image, (row_corners,col_corners), corners, ret)\n",
    "                    plt.subplot(5,4,idx)\n",
    "                    plt.imshow(image)  \n",
    "\n",
    "        ret, self.mtx_, self.dist_, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints,self.img_size_,None,None)\n",
    "        \n",
    "\n",
    "    \n",
    "    def saveCalibrationData(self,path=\"camera_cal/cal_data.p\"):\n",
    "        \"\"\"\n",
    "        Save the camera matrix (mtx_) and vector of distortion coefficients(dist_)\n",
    "        :param self: referenc of the class instance\n",
    "        :param path: path to save data\n",
    "        \"\"\"\n",
    "        dist_pickle = {}\n",
    "        dist_pickle[\"mtx\"] = self.mtx_\n",
    "        dist_pickle[\"dist\"] = self.dist_\n",
    "        pickle.dump( dist_pickle, open(path + \"cal_data.p\", \"wb\" ) )\n",
    "        \n",
    "    def getCalibrationData(self,path_name=\"camera_cal/cal_data.p\"):\n",
    "        \"\"\"\n",
    "        Get the camera matrix (mtx_) and vector of distortion coefficients(dist_)\n",
    "        from a saved file\n",
    "        :param self: referenc of the class instance\n",
    "        :param path_name: path to get data\n",
    "        \"\"\"\n",
    "        file = open(path_name, 'rb')\n",
    "        data = pickle.load(file)\n",
    "        file.close()\n",
    "        self.mtx_ = data['mtx']\n",
    "        self.dist_ = data['dist']\n",
    "        \n",
    "    def correctImageDistortion(self,image):\n",
    "        \"\"\"\n",
    "        Correct the image distortion\n",
    "        :param self: referenc of the class instance\n",
    "        :param image: Source image\n",
    "        :return Undistorted Image\n",
    "        \"\"\"\n",
    "        self.img_shape_ = image.shape\n",
    "        return cv2.undistort(image, self.mtx_, self.dist_, None, self.mtx_)\n",
    "    \n",
    "    def applyColorAndGradient(self,image):\n",
    "        \"\"\"\n",
    "        High Level function to apply color and gradient thresholds\n",
    "        :param self: referenc of the class instance\n",
    "        :param image: Source image\n",
    "        :return Binary Image combined with the methods\n",
    "        \"\"\"\n",
    "        r_channel, _, _ = getImageChannels(image,space='RGB')\n",
    "        _, _, s_channel = getImageChannels(image,space='HLS')\n",
    "        \n",
    "        r_channel = darkenImage(r_channel,self.gamma_)\n",
    "        \n",
    "        r_binary = binarizeImage(r_channel,self.r_channel_thresh_,cv2.THRESH_BINARY)\n",
    "        s_binary = binarizeImage(s_channel,self.r_channel_thresh_,cv2.THRESH_BINARY)\n",
    "        \n",
    "        s_binary_auto = binarizeImage(s_channel,self.s_channel_thresh_,cv2.THRESH_BINARY | cv2.THRESH_TRIANGLE)\n",
    "        \n",
    "        grad_x,_ = getSobelGradient(r_channel,'x',self.grad_x_thresh_)\n",
    "\n",
    "        combined_binary = np.zeros_like(r_binary)\n",
    "\n",
    "        combined_binary[((r_binary == 1) & ((s_binary == 1) | (s_binary_auto == 1) | (grad_x == 1)))] = 1\n",
    "        return combined_binary\n",
    "        \n",
    "        \n",
    "    def restorePerspective(self,warped,undist,left_fitx,right_fitx,ploty):\n",
    "        \"\"\"\n",
    "        Restore the bird's eye image and draw the lane\n",
    "        :param self: referenc of the class instance\n",
    "        :param warped: Birds eye image\n",
    "        :param undist: Unditorted image\n",
    "        :param left_fitx: Left line \n",
    "        :param right_fitx: Right line \n",
    "        :param ploty: Vector of Y values\n",
    "        :return Restored Image\n",
    "        \"\"\"\n",
    "        warp_zero = np.zeros_like(warped).astype(np.uint8)\n",
    "        color_warp = np.dstack((warp_zero, warp_zero, warp_zero))\n",
    "\n",
    "        pts_left = np.array([np.transpose(np.vstack([left_fitx, ploty]))])\n",
    "        pts_right = np.array([np.flipud(np.transpose(np.vstack([right_fitx, ploty])))])\n",
    "        pts = np.hstack((pts_left, pts_right))\n",
    "\n",
    "        cv2.fillPoly(color_warp, np.int_([pts]), (0,255, 0))\n",
    "\n",
    "        newwarp = transformPerspective(color_warp,self.dst_points_,self.src_points_)\n",
    "        result = cv2.addWeighted(undist, 1, newwarp, 0.3, 0)\n",
    "        \n",
    "        return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lane Finder Class\n",
    "\n",
    "This class keep the information for tranform an image in to a Bird's eye binarizate image to find the lane marks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LaneFinder:\n",
    "    \"\"\"\n",
    "    Class that finds the lane lines using the ImageProcessor Class\n",
    "    and some methods to fit the lane marks into a curve.\n",
    "    \"\"\" \n",
    "    def __init__(self,image_shape=(720,1280,3)):\n",
    "        \"\"\"\n",
    "        Class constructor, all the class variables are defined here \n",
    "        :param self: referenc of the class instance\n",
    "        :param img_shape: shape of the image\n",
    "        \"\"\"\n",
    "        self.img_processor_ = ImageProcessor()\n",
    "        self.img_processor_.getCalibrationData()\n",
    "        \n",
    "        self.image_shape_ = image_shape\n",
    "        \n",
    "        self.number_sliding_windows_  = 9\n",
    "        self.windows_width_           = 70\n",
    "        self.window_height_           = np.int(self.image_shape_[0]//self.number_sliding_windows_)\n",
    "        self.windows_min_pixels_      = 70\n",
    "        \n",
    "        self.filter_order_ = 15\n",
    "        \n",
    "        self.left_x_base_  = 0\n",
    "        self.right_x_base_ = 0\n",
    "        \n",
    "        self.current_left_fit_  = None\n",
    "        self.current_right_fit_ = None\n",
    "        \n",
    "        self.filtered_left_fit_  = []\n",
    "        self.filtered_right_fit_ = []\n",
    "        \n",
    "        self.left_fit_x_         = None\n",
    "        self.right_fit_x_        = None\n",
    "        self.mean_fit_x_         = None\n",
    "        self.plot_y_             = np.linspace(0, image_shape[0]-1, image_shape[0])\n",
    "        \n",
    "        self.y_max_curvature_     = 0\n",
    "        self.center_lane_offset_  = 0\n",
    "        self.curvature_           = 0\n",
    "        \n",
    "        self.need_deep_search_   = True\n",
    "        self.use_last_fit_       = False\n",
    "        \n",
    "        self.ym_per_pix_ = 15.0/260\n",
    "        self.xm_per_pix_ = 3.7/600\n",
    "        \n",
    "    def locateBaseLines(self,image,pix_per_bin=40):\n",
    "        \"\"\"\n",
    "        Compute the histogram of the image to locate the Left and Right base lines\n",
    "        :param self: referenc of the class instance\n",
    "        :param image: Source image\n",
    "        :param pix_per_bin: Number of pixels for each bin\n",
    "        \"\"\"\n",
    "        self.image_shape_ = image.shape\n",
    "\n",
    "        windows = self.image_shape_[1]//pix_per_bin\n",
    "        hist = []\n",
    "        for window in range(windows):\n",
    "            w_low = window * pix_per_bin\n",
    "            w_high = (window +1) * pix_per_bin\n",
    "            hist.append(np.max(np.sum(image[:,w_low:w_high], axis=0)))\n",
    "        \n",
    "        self.left_x_base_ = (np.argmax(hist[:windows//2]) * pix_per_bin) + pix_per_bin//2\n",
    "        self.right_x_base_ = (np.argmax(hist[windows//2:]) + self.image_shape_[1]//pix_per_bin//2) * pix_per_bin + pix_per_bin//2\n",
    "        \n",
    "        n_pix_left = np.max(hist[:windows//2])\n",
    "        n_pix_right = np.max(hist[windows//2:])\n",
    "        \n",
    "        dist_base_lines = self.right_x_base_-self.left_x_base_\n",
    "        \n",
    "        if (n_pix_left < 50 or n_pix_right < 50):\n",
    "            self.use_last_fit_ = True\n",
    "        \n",
    "        elif (dist_base_lines < 300 or dist_base_lines > 900):\n",
    "            self.use_last_fit_ = True\n",
    "        \n",
    "        else:\n",
    "            self.use_last_fit_ = False\n",
    "        \n",
    "    def deepLineSearch(self,image):\n",
    "        \"\"\"\n",
    "        Search the line using a deep method, creating sliding windows\n",
    "        Fit the lane pixels in a polynomial curve\n",
    "        :param self: referenc of the class instance\n",
    "        :param image: Source image\n",
    "        \"\"\"\n",
    "        self.need_deep_search_ = False    \n",
    "        out_img = np.dstack((image, image, image))\n",
    "        out_img = out_img * 255\n",
    "        \n",
    "        nonzero = image.nonzero()\n",
    "        nonzeroy = np.array(nonzero[0])\n",
    "        nonzerox = np.array(nonzero[1])\n",
    "        \n",
    "        left_lane_inds = []\n",
    "        right_lane_inds = []\n",
    "        \n",
    "        for window in range(self.number_sliding_windows_):\n",
    "            win_y_low  = image.shape[0] - (window + 1 ) * self.window_height_\n",
    "            win_y_high = image.shape[0] - window * self.window_height_\n",
    "\n",
    "            win_xleft_low = self.left_x_base_ - self.windows_width_\n",
    "            win_xleft_high = self.left_x_base_ + self.windows_width_\n",
    "            win_xright_low = self.right_x_base_ - self.windows_width_\n",
    "            win_xright_high = self.right_x_base_ + self.windows_width_\n",
    "\n",
    "            cv2.rectangle(out_img,(win_xleft_low,win_y_low),\n",
    "            (win_xleft_high,win_y_high),(0,255,0), 5) \n",
    "            cv2.rectangle(out_img,(win_xright_low,win_y_low),\n",
    "            (win_xright_high,win_y_high),(0,255,0), 5) \n",
    "\n",
    "            good_left_inds  = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & \n",
    "                               (nonzerox >= win_xleft_low) & (nonzerox < win_xleft_high)).nonzero()[0]\n",
    "            good_right_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & \n",
    "                               (nonzerox >= win_xright_low) & (nonzerox < win_xright_high)).nonzero()[0]\n",
    "\n",
    "            left_lane_inds.append(good_left_inds)\n",
    "            right_lane_inds.append(good_right_inds)\n",
    "\n",
    "            if (good_left_inds.shape[0] > self.windows_min_pixels_):\n",
    "                self.left_x_base_ = np.int(np.mean(nonzerox[good_left_inds]))\n",
    "            if (good_right_inds.shape[0] > self.windows_min_pixels_):        \n",
    "                self.right_x_base_ = np.int(np.mean(nonzerox[good_right_inds]))\n",
    "        \n",
    "        try:\n",
    "            left_lane_inds = np.concatenate(left_lane_inds)\n",
    "            right_lane_inds = np.concatenate(right_lane_inds)\n",
    "        except ValueError:\n",
    "            pass\n",
    "\n",
    "        leftx  = nonzerox[left_lane_inds]\n",
    "        lefty  = nonzeroy[left_lane_inds] \n",
    "        rightx = nonzerox[right_lane_inds]\n",
    "        righty = nonzeroy[right_lane_inds]\n",
    "        \n",
    "        if (len(leftx) < 3000 or len(rightx) < 3000):\n",
    "            self.need_deep_search_ = True\n",
    "            self.use_last_fit_ = True\n",
    "            return None\n",
    "        \n",
    "        try:\n",
    "            self.current_left_fit_ = np.polyfit(lefty,leftx,2)\n",
    "            self.current_right_fit_ = np.polyfit(righty,rightx,2)\n",
    "            \n",
    "            self.left_fit_x_ = self.current_left_fit_[0]*self.plot_y_**2 + self.current_left_fit_[1]*self.plot_y_ + self.current_left_fit_[2]\n",
    "            self.right_fit_x_ = self.current_right_fit_[0]*self.plot_y_**2 + self.current_right_fit_[1]*self.plot_y_ + self.current_right_fit_[2]\n",
    "                \n",
    "        except:\n",
    "            self.need_deep_search_ = True\n",
    "            self.use_last_fit_ = True\n",
    "            pass\n",
    "        \n",
    "        left_slope_bottom, right_slope_bottom, left_slope_top, right_slope_top = self.getSlopes()\n",
    "        \n",
    "        abs_diff_slope_bottom = abs(right_slope_bottom - left_slope_bottom)\n",
    "        abs_diff_slope_top= abs(right_slope_top - left_slope_top)\n",
    "        \n",
    "        if (abs_diff_slope_bottom > 0.2 or  abs_diff_slope_top > 0.2):\n",
    "            self.need_deep_search_ = True\n",
    "            self.use_last_fit_ = True\n",
    "\n",
    "        elif (np.in1d(self.right_fit_x_.astype(int),self.left_fit_x_.astype(int)).any()):\n",
    "            self.need_deep_search_ = True\n",
    "            self.use_last_fit_ = True\n",
    "        \n",
    "        elif(self.need_deep_search_ == False):\n",
    "            self.linesFilter()\n",
    "            \n",
    "            self.left_fit_x_ = self.current_left_fit_[0]*self.plot_y_**2 + self.current_left_fit_[1]*self.plot_y_ + self.current_left_fit_[2]\n",
    "            self.right_fit_x_ = self.current_right_fit_[0]*self.plot_y_**2 + self.current_right_fit_[1]*self.plot_y_ + self.current_right_fit_[2]\n",
    "\n",
    "            self.y_max_curvature_ = np.max(self.plot_y_)\n",
    "            \n",
    "            self.need_deep_search_ = False\n",
    "                \n",
    "        \n",
    "    \n",
    "        out_img[lefty, leftx] = [255, 0, 0]\n",
    "        out_img[righty, rightx] = [0, 0, 255]\n",
    "        \n",
    "        \n",
    "        \n",
    "        return out_img\n",
    "            \n",
    "    def smartLineSearch(self,image):\n",
    "        \"\"\"\n",
    "        Search the line using a smart method, searching just in the most probably\n",
    "        Fit the lane pixels in a polynomial curve\n",
    "        :param self: reference of the class instance\n",
    "        :param image: Source image\n",
    "        \"\"\"\n",
    "        self.need_deep_search_ = False\n",
    "        out_img = np.dstack((image, image, image))\n",
    "        out_img = out_img * 255\n",
    "        \n",
    "        nonzero  = image.nonzero()\n",
    "        nonzeroy = np.array(nonzero[0])\n",
    "        nonzerox = np.array(nonzero[1])\n",
    "\n",
    "        left_lane_inds  = ((nonzerox > (self.current_left_fit_[0]*(nonzeroy**2) + self.current_left_fit_[1]*nonzeroy + \n",
    "                                self.current_left_fit_[2] - self.windows_width_)) &\n",
    "                           (nonzerox < (self.current_left_fit_[0]*(nonzeroy**2) + self.current_left_fit_[1]*nonzeroy +\n",
    "                                self.current_left_fit_[2] + self.windows_width_)))\n",
    "        right_lane_inds = ((nonzerox > (self.current_right_fit_[0]*(nonzeroy**2) + self.current_right_fit_[1]*nonzeroy +\n",
    "                                self.current_right_fit_[2] - self.windows_width_)) &\n",
    "                           (nonzerox < (self.current_right_fit_[0]*(nonzeroy**2) + self.current_right_fit_[1]*nonzeroy +\n",
    "                                self.current_right_fit_[2] + self.windows_width_)))\n",
    "        \n",
    "        leftx  = nonzerox[left_lane_inds]\n",
    "        lefty  = nonzeroy[left_lane_inds] \n",
    "        rightx = nonzerox[right_lane_inds]\n",
    "        righty = nonzeroy[right_lane_inds]\n",
    "        \n",
    "        if (len(leftx) < 2500 or len(rightx) < 2500):\n",
    "            self.need_deep_search_ = True\n",
    "            return None\n",
    "        elif  (len(leftx) > 35000 or len(rightx) > 35000):\n",
    "            self.need_deep_search_ = True\n",
    "            return None\n",
    "        \n",
    "        try:\n",
    "            self.current_left_fit_ = np.polyfit(lefty,leftx,2)\n",
    "            self.current_right_fit_ = np.polyfit(righty,rightx,2)\n",
    "            \n",
    "            self.left_fit_x_ = self.current_left_fit_[0]*self.plot_y_**2 + self.current_left_fit_[1]*self.plot_y_ + self.current_left_fit_[2]\n",
    "            self.right_fit_x_ = self.current_right_fit_[0]*self.plot_y_**2 + self.current_right_fit_[1]*self.plot_y_ + self.current_right_fit_[2]\n",
    "\n",
    "        except:\n",
    "            self.need_deep_search_ = True\n",
    "            pass\n",
    "        \n",
    "        \n",
    "        left_slope_bottom, right_slope_bottom, left_slope_top, right_slope_top = self.getSlopes()\n",
    "        abs_diff_slope_bottom = abs(right_slope_bottom - left_slope_bottom)\n",
    "        abs_diff_slope_top= abs(right_slope_top - left_slope_top)\n",
    "\n",
    "        if (abs_diff_slope_bottom > 0.2 or  abs_diff_slope_top > 0.2):\n",
    "            self.need_deep_search_ = True\n",
    "            \n",
    "        elif (np.in1d(self.right_fit_x_.astype(int),self.left_fit_x_.astype(int)).any()):\n",
    "            self.need_deep_search_ = True\n",
    "        \n",
    "        elif(np.max(self.right_fit_x_) >= 1280 or np.max(self.left_fit_x_) <= 0):\n",
    "            self.need_deep_search_ = True\n",
    "        \n",
    "        elif(self.need_deep_search_ == False):\n",
    "            self.linesFilter()\n",
    "            \n",
    "            self.left_fit_x_ = self.current_left_fit_[0]*self.plot_y_**2 + self.current_left_fit_[1]*self.plot_y_ + self.current_left_fit_[2]\n",
    "            self.right_fit_x_ = self.current_right_fit_[0]*self.plot_y_**2 + self.current_right_fit_[1]*self.plot_y_ + self.current_right_fit_[2]\n",
    "\n",
    "            self.y_max_curvature_ = np.max(self.plot_y_)\n",
    "        \n",
    "            \n",
    "        window_img = np.zeros_like(out_img)\n",
    "        out_img[nonzeroy[left_lane_inds], nonzerox[left_lane_inds]] = [255, 0, 0]\n",
    "        out_img[nonzeroy[right_lane_inds], nonzerox[right_lane_inds]] = [0, 0, 255]\n",
    "\n",
    "        left_line_window1 = np.array([np.transpose(np.vstack([self.left_fit_x_-self.windows_width_, self.plot_y_]))])\n",
    "        left_line_window2 = np.array([np.flipud(np.transpose(np.vstack([self.left_fit_x_+self.windows_width_, \n",
    "                                  self.plot_y_])))])\n",
    "        left_line_pts = np.hstack((left_line_window1, left_line_window2))\n",
    "\n",
    "        right_line_window1 = np.array([np.transpose(np.vstack([self.right_fit_x_-self.windows_width_, self.plot_y_]))])\n",
    "        right_line_window2 = np.array([np.flipud(np.transpose(np.vstack([self.right_fit_x_+self.windows_width_,self.plot_y_])))])\n",
    "        right_line_pts = np.hstack((right_line_window1, right_line_window2))\n",
    "\n",
    "        mid_line_window1 = np.array([np.transpose(np.vstack([self.mean_fit_x_-3, self.plot_y_]))])\n",
    "        mid_line_window2 = np.array([np.flipud(np.transpose(np.vstack([self.mean_fit_x_+3,self.plot_y_])))])\n",
    "        mid_line_pts = np.hstack((mid_line_window1, mid_line_window2))\n",
    "\n",
    "        cv2.fillPoly(window_img, np.int_([left_line_pts]), (0,255, 0))\n",
    "        cv2.fillPoly(window_img, np.int_([right_line_pts]), (0,255, 0))\n",
    "        cv2.fillPoly(window_img, np.int_([mid_line_pts]), (255,255, 0))\n",
    "        out_img = cv2.addWeighted(out_img, 1, window_img, 0.3, 0)\n",
    "        \n",
    "        return out_img\n",
    "            \n",
    "    def laneCurvature(self):\n",
    "        \"\"\"\n",
    "        Compute the lane curvature using the mean line of the lane.\n",
    "        :param self: reference of the class instance\n",
    "        \"\"\"\n",
    "        self.mean_fit_ = (self.current_right_fit_ + self.current_left_fit_)/2 \n",
    "        self.mean_fit_x_ = self.mean_fit_[0]*(self.plot_y_**2) + self.mean_fit_[1]*self.plot_y_ + self.mean_fit_[2]\n",
    "        \n",
    "        y_eval = self.plot_y_ * self.ym_per_pix_\n",
    "        self.xm_per_pix_ = 3.7 / (np.mean(self.right_fit_x_[360:])-np.mean(self.left_fit_x_[360:]))\n",
    "        \n",
    "        A = (self.xm_per_pix_ / (self.ym_per_pix_ ** 2))* self.mean_fit_[0]\n",
    "        B = (self.xm_per_pix_ / self.ym_per_pix_) * self.mean_fit_[1]\n",
    "        \n",
    "        curvature = ((1+(2*A*y_eval + B)**2)**(3/2)) / (2*A)\n",
    "        \n",
    "        self.curvature_ = np.mean(curvature)\n",
    "        \n",
    "        if abs(self.curvature_) > 10000: #10km\n",
    "            self.curvature_ = 10000\n",
    "    \n",
    "    def carLaneCenterDesviation(self):\n",
    "        \"\"\"\n",
    "        Compute the car's desviation to te lane center\n",
    "        :param self: reference of the class instance\n",
    "        \"\"\"\n",
    "        lane_center = (self.right_fit_x_[719] + self.left_fit_x_[719])/2.0\n",
    "        self.center_lane_offset_ = (self.image_shape_[1]/2 - lane_center) * self.xm_per_pix_\n",
    "\n",
    "                    \n",
    "    def linesFilter(self):\n",
    "        \"\"\"\n",
    "        Line fit values filter to smooth the lane detection in each iteration\n",
    "        Low-pass filter\n",
    "        :param self: reference of the class instance\n",
    "        \"\"\"\n",
    "        if (len(self.filtered_left_fit_) >= self.filter_order_):\n",
    "            self.filtered_left_fit_.pop(0)\n",
    "            self.filtered_right_fit_.pop(0)\n",
    "        \n",
    "        self.filtered_left_fit_.append(self.current_left_fit_)\n",
    "        self.filtered_right_fit_.append(self.current_right_fit_)\n",
    "        \n",
    "        self.current_left_fit_ = np.sum(self.filtered_left_fit_, axis=0)/len(self.filtered_left_fit_)\n",
    "        self.current_right_fit_ = np.sum(self.filtered_right_fit_, axis=0)/len(self.filtered_right_fit_)\n",
    "        \n",
    "    def getSlopes(self):\n",
    "        \"\"\"\n",
    "        Funtion to get the slopes of each line (left-right).\n",
    "        :param self: reference of the class instance\n",
    "        \"\"\"\n",
    "        left_bottom_x = self.right_fit_x_[719]\n",
    "        left_mid_x = self.right_fit_x_[360]\n",
    "        left_top_x = self.right_fit_x_[0]\n",
    "        \n",
    "        right_bottom_x = self.right_fit_x_[719]\n",
    "        right_mid_x = self.right_fit_x_[360]\n",
    "        right_top_x = self.right_fit_x_[0]\n",
    "        \n",
    "        left_slope_bottom = (360 - 719) / (left_mid_x - left_bottom_x +  0.0000001)\n",
    "        right_slope_bottom = (360 - 719) / (right_mid_x - right_bottom_x +  0.0000001)\n",
    "        \n",
    "        left_slope_top = (0 - 360) / (left_top_x - left_mid_x +  0.0000001)\n",
    "        right_slope_top = (0 - 360) / (right_top_x - right_mid_x +  0.0000001)\n",
    "        \n",
    "        return left_slope_bottom, right_slope_bottom, left_slope_top, right_slope_top\n",
    "    \n",
    "    def runPipeline(self,image):\n",
    "        \"\"\"\n",
    "        Funtion to run all the pipeline\n",
    "        :param self: reference of the class instance\n",
    "        \"\"\"\n",
    "        #Image Processing\n",
    "        undist = self.img_processor_.correctImageDistortion(image)\n",
    "        \n",
    "        binary_undist = self.img_processor_.applyColorAndGradient(undist)\n",
    "        \n",
    "        warped_binary = transformPerspective(binary_undist,self.img_processor_.src_points_,\n",
    "                                             self.img_processor_.dst_points_)\n",
    "        \n",
    "        warped_binary = cv2.morphologyEx(warped_binary, cv2.MORPH_OPEN, np.ones((3,3)))\n",
    "        warped_binary = cv2.morphologyEx(warped_binary, cv2.MORPH_TOPHAT, np.ones((2,65)))\n",
    "                \n",
    "        #Lane Detection\n",
    "        search_image = None\n",
    "\n",
    "        if (self.need_deep_search_ == False):\n",
    "            search_image = self.smartLineSearch(warped_binary)\n",
    "        \n",
    "        if (self.need_deep_search_ == True):\n",
    "            self.locateBaseLines(warped_binary)\n",
    "            if (self.use_last_fit_ == False):\n",
    "                search_image = self.deepLineSearch(warped_binary)\n",
    " \n",
    "        if(self.use_last_fit_ == False):\n",
    "            self.laneCurvature()\n",
    "            self.carLaneCenterDesviation()\n",
    "            \n",
    "        elif((self.use_last_fit_ == True or self.need_deep_search_ == True) and len(self.filtered_left_fit_) > 0):\n",
    "            self.current_left_fit_ = np.sum(self.filtered_left_fit_, axis=0)/len(self.filtered_left_fit_)\n",
    "            self.current_right_fit_ = np.sum(self.filtered_right_fit_, axis=0)/len(self.filtered_right_fit_)\n",
    "            \n",
    "            self.left_fit_x_ = self.current_left_fit_[0]*self.plot_y_**2 + self.current_left_fit_[1]*self.plot_y_ + self.current_left_fit_[2]\n",
    "            self.right_fit_x_ = self.current_right_fit_[0]*self.plot_y_**2 + self.current_right_fit_[1]*self.plot_y_ + self.current_right_fit_[2]\n",
    "            \n",
    "            self.use_last_fit_ = False\n",
    "        \n",
    "        if (self.current_left_fit_ is not None):\n",
    "            final = self.img_processor_.restorePerspective(warped_binary,undist,self.left_fit_x_, \\\n",
    "                                                self.right_fit_x_,self.plot_y_)\n",
    "\n",
    "            offset_string = \"Center offset: %.2f m\" % self.center_lane_offset_\n",
    "            curvature_string = \"Radius of curvature: %.2f km\" % (abs(self.curvature_)/1000.0)\n",
    "            \n",
    "            if (abs(self.curvature_) >= 5000):\n",
    "                lane_string = \"Straight Lane\"\n",
    "            elif (self.curvature_ >= 0 and self.curvature_ < 5000):\n",
    "                lane_string = \"Right Curve\"\n",
    "            elif (self.curvature_ < 0 and self.curvature_ > -5000):\n",
    "                lane_string = \"Left Curve\"\n",
    "\n",
    "            cv2.putText(final,curvature_string,(50,50), cv2.FONT_HERSHEY_SIMPLEX, 1,(255,255,255),2,cv2.LINE_AA)\n",
    "            cv2.putText(final,offset_string,(50,100), cv2.FONT_HERSHEY_SIMPLEX, 1,(255,255,255),2,cv2.LINE_AA)\n",
    "            cv2.putText(final,lane_string,(50,150), cv2.FONT_HERSHEY_SIMPLEX, 1,(255,255,255),2,cv2.LINE_AA)\n",
    "        else:\n",
    "            final = undist\n",
    "        \n",
    "        if search_image is  None:\n",
    "            search_image = np.dstack((warped_binary, warped_binary, warped_binary))\n",
    "            search_image = search_image * 255\n",
    "            \n",
    "        return np.concatenate((search_image,final), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test on Videos\n",
    "\n",
    "Provided videos:\n",
    "\n",
    "`test_videos/project_video.mp4`\n",
    "\n",
    "`test_videos/challenge_video.mp4`\n",
    "\n",
    "`test_videos/harder_challenge_video.mp4`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_names = os.listdir(\"test_videos/\")\n",
    "lane_finder = LaneFinder()\n",
    "\n",
    "for video_name in video_names:\n",
    "    video_output = 'output_videos/' + video_name\n",
    "    clip = VideoFileClip('test_videos/' + video_name)\n",
    "    video_clip = clip.fl_image(lane_finder.runPipeline)\n",
    "    video_clip.write_videofile(video_output, audio=False)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
